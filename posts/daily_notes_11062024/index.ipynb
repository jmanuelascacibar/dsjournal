{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Daily Note - 11-06-2024\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "    toc: true\n",
    "    toc-levels: 4\n",
    "    toc-expand: 4\n",
    "jupyter: python3  \n",
    "author: \"JM Ascacibar\"\n",
    "date: \"2024-06-10\"\n",
    "categories: \n",
    "  - PyCaret\n",
    "  - PyTorch\n",
    "  - Keras\n",
    "  - sktime\n",
    "  - Prophet\n",
    "  - yfinance\n",
    "  - pandas time series\n",
    "  - transformations\n",
    "  - ACF PACF\n",
    "  - time series\n",
    "  - visualizations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Installation PyCaret, PyTorch, Keras, sktime, Prophet, yfinance, Set up time index, index frequency, Log transformation, Box-cox transformation, ACF and PACF, everything is reflected in today's price, ACF and PACF, Stationarity and unit-root, Augmented Dickey-Fuller test*\n",
    "\n",
    "![](designer.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Daily Note - 11/06/2024\n",
    "\n",
    "## Installation of PyCaret\n",
    "\n",
    "[Documentation](https://pycaret.gitbook.io/docs/get-started/installation)\n",
    "\n",
    "```python\t\n",
    "# install full version\n",
    "pip install pycaret[full]\n",
    "```\t\n",
    "\n",
    "## Installation of PyTorch\n",
    "\n",
    "First check the version of CUDA installed in your system using `nvidia-smi`. Install PyTorch following the [documentation](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "## Installation of Keras\n",
    "\n",
    "You can install Keras from pip:\n",
    "\n",
    "```python\n",
    "pip install --upgrade keras\n",
    "``` \n",
    "\n",
    "## Installation of sktime\n",
    "\n",
    "To install sktime:\n",
    "\n",
    "```python\n",
    "pip install sktime[all_extras]\n",
    "``` \n",
    "\n",
    "## Installation of Prophet\n",
    "\n",
    "```python\n",
    "conda install -c conda-forge prophet\n",
    "```\n",
    "\n",
    "[Documentation](https://facebook.github.io/prophet/)\n",
    "\n",
    "## Installation of yfinance\n",
    "\n",
    "```python\n",
    "pip install yfinance\n",
    "``` \n",
    "## Download a time series data with yfinance\n",
    "\n",
    "```python\n",
    "import yfinance as yf\n",
    "data = yf.download(\"AAPL\", start=\"2021-01-01\", end=\"2021-12-31\")\n",
    "```\n",
    "\n",
    "## Set up time index\n",
    "\n",
    "When you are working with time series data, you need to set the time index.\n",
    "\n",
    "```python\n",
    "#air.index -> strings of dates (monthly)\n",
    "air.index = pd.to_datetime(air.index).to_period('M')\n",
    "```\n",
    "\n",
    "## Set the index frequency to business day\n",
    "\n",
    "Most of the data providers provide the data with the correct format.\n",
    "However, you still need to check the frequency of the data.\n",
    "If the frequency is not specficied, you need to set it.\n",
    "\n",
    "For example, you will see that the frequency is none:\n",
    "\n",
    "```markdown\n",
    "DatetimeIndex(['2021-12-22', '2021-12-23', '2021-12-27', '2021-12-28',\n",
    "               '2021-12-29', '2021-12-30', '2021-12-31', '2022-01-03',\n",
    "               '2022-01-04', '2022-01-05',\n",
    "               ...\n",
    "               '2024-04-17', '2024-04-18', '2024-04-19', '2024-04-22',\n",
    "               '2024-04-23', '2024-04-24', '2024-04-25', '2024-04-26',\n",
    "               '2024-04-29', '2024-04-30'],\n",
    "              dtype='datetime64[ns]', name='Date', length=591, freq=None)\n",
    "``` \n",
    "\n",
    "\n",
    "```python\n",
    "aapl_close = aapl_close.asfreq('B')\n",
    "```\n",
    "\n",
    "Do not forget that the next step is to fill the missing values. One method that you can use is \n",
    "forward fill. This means that is tomorrow the market is closed and today price is $100 then \n",
    "the price of tomorrow will be $100.\n",
    "\n",
    "```python\n",
    "# aapl_close = aapl_close.ffill(method='ffill') deprecated\n",
    "aapl_close = aapl_close.ffill()\n",
    "```\n",
    "\n",
    "## Plot a time series with index period\n",
    "\n",
    "If you are trying to plot a time series data with index period, you need to be aware that matplotlib does not support\n",
    "it. It's going to give a error telling you that the index should be a string or a real number. \n",
    "\n",
    "So if you need your index as a period because you are going to model it with PyCaret or other library, what you can \n",
    "do is the folling:\n",
    "\n",
    "```python\n",
    "# air.index.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(air.index.to_timestamp(), air.Passengers, label='Airline Passengers')\n",
    "plt.title('Airline Passengers')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "This will convert the index to a timestamp and you will be able to plot it.\n",
    "\n",
    "\n",
    "## Log transformation in time series.\n",
    "\n",
    "When you have a time series that increase its variance over time, you can apply a log transformation to stabilize it.\n",
    "This is one way. There're different ways like power transformation (like the square root) or box-cox transformation.\n",
    "\n",
    "Be aware that these transformation can alter the interpretation of the data. The way to determine \n",
    "which transformation to use is to try different ones and see which one fits the best. \n",
    "\n",
    "## Box-cox transformation\n",
    "Probably the best transformation is the Box-Cox transformation because it's going to look for the \n",
    "parameter the best transform the data to a normal distribution. \n",
    "\n",
    "The equation looks like this:\n",
    "$$w_t = \\begin{cases} \\log(y_t) & \\text{if } \\lambda = 0 \\\\ \\frac{y_t^\\lambda - 1}{\\lambda} & \\text{if } \\lambda \\neq 0 \\end{cases}$$\n",
    "where $y_t$ is the original data, $w_t$ is the transformed data, and $\\lambda$ is the transformation parameter.\n",
    "\n",
    "When lambda is 0, the transformation is the log transformation. When lambda is 1, our data shift dow, but the the shape \n",
    "of the data doesn't change. So if the optimal lambda is 1, we don't need to do anything, the data \n",
    "is already normally distributed. \n",
    "\n",
    "You can find the optimal value of lambda using the `scipy.stats.boxcox` function.\n",
    "\n",
    "```python\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "air['Passengers_boxcox'], opt_l = boxcox(air.Passengers)\n",
    "```\t\n",
    "\n",
    "where `opt_l` is the optimal lambda value.\n",
    "\n",
    "## ACF and PACF\n",
    "\n",
    "ACF (autocorrelation function) is a tool to identify the relationship between the current value and the previous values.\n",
    "It measures the autocorrelation of a time series also called serial correlation. Measure the correlation between the time series and a lagged version of itself. It shows the degree to which the past values are predictive of future values.\n",
    "As always happen with correlation, be aware it's measuring linear correlation so it's not going to capture non-linear relationships.\n",
    "\n",
    "We can use it as a diagnostic tool to identify the order (lags) of the AR and MA components of the ARIMA model. \n",
    "Also, it provides information about the trend and seasonality of the time series. \n",
    "\n",
    "The following image plot the ACF and PACF of the Airline Passengers dataset.\n",
    "\n",
    "![](acf_pacf.png)\n",
    "\n",
    "Looking at the ACF plot, we can notice there's a downward sloping in term of the magnitude \n",
    "of autocorrelation. That means that there's a trend in the data. The wave pattern in the ACF plot\n",
    "is a sign of seasonality. For example in our case we have a wave pattern every 12 months (autocorrelation peaks). This means that there's high correlation between $y_t$ and $y_{t-12}$.\n",
    "\n",
    "PACF (Partial autocorrelation function) measures the correlation between the time series and a lagged version of itself but after removing the effect of the intermediate lags. It provides a more fine-grained view of the relationship between the current value and its immediate past. For example, maybe the correlation between $y_t$ and $y_{t-2}$ is highly correlated because both are highly correlated with $y_{t-1}$. The PACF will show that the correlation between $y_t$ and $y_{t-2}$ is not significant after removing the effect of $y_{t-1}$.\n",
    "\n",
    "\n",
    "## PACF of financial time series ('everything is reflected in today's price')\n",
    "\n",
    "The following plot shows the Apple stock price from 2021-12-22 to 2024-05-01. \n",
    "\n",
    "![](aapl.png)\n",
    "\n",
    "This is a not-well behaved time series where trend changes over time, there's not clear seasonality, and the variance is not constant. \n",
    "\n",
    "![](aapl_acf_pacf.png)\n",
    "\n",
    "The ACF plot shows that there's a high correlation between the current value and the previous values. This is a sign of trend in the data. The PACF plot shows that there's a high correlation between the current value and the previous value but not with the other lags. This is quite common in stock prices. The partial autocorrelation in lag 1 is almost 1, today's price and yesterday's price. So if you control for the effect of intermediate lags there's nothing left. At least, \n",
    "this one lag is capturing most of the linear relationship. \n",
    "\n",
    "So if you want to predict the stock price of tomorrow, it seems that the best predictor is today's price. Here we go with the common saying that everything is reflected in today's price.\n",
    "\n",
    "This is the random walk model. Where $y_{t+1 }= y_{t} + \\epsilon_t$. The best predictor of tomorrow's price is today's price.\n",
    "\n",
    "## Stationarity and unit-root\n",
    "\n",
    "A time series is stationary if its statistical properties such as mean, variance, and autocorrelation are constant over time. This means that the time series is not dependent on time.\n",
    "\n",
    "Stationary time series are easier to model because we can assume that the statistical properties are constant over time. \n",
    "\n",
    "A time series with a unit root is non-stationary and can be described by a stochastic trend \n",
    "which first difference will be stationary.\n",
    "\n",
    "\n",
    "## Augmented Dickey-Fuller test\n",
    "\n",
    "The Augmented Dickey-Fuller test is a statistical test that can be used to test whether a time series has a unit root or not. This means to test if the time series is stationary or not.\n",
    "If the p-value is less than a significance level, we reject the null hypothesis that the\n",
    "time series is non-stationary. This suggests strong evidence against the null hypothesis, indicating the series is stationary. If the p-value is greater than the chosen significance level, fail to reject the null hypothesis. This suggests weak evidence against the null hypothesis, indicating the series is non-stationary.\n",
    "\n",
    "[Documentation](https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html)\n",
    "\n",
    "\n",
    "You can use the `adfuller` function from the `statsmodels` library.\n",
    "\n",
    "```python\n",
    "ad_result = adfuller(air.Passengers)\n",
    "print('ADF Statistic:', ad_result[0])\n",
    "print('p-value:', ad_result[1])\n",
    "```\n",
    "\n",
    "But if you want to make it more readable, you can create a function that will print the results.\n",
    "\n",
    "```python\n",
    "def adf_test(ts):\n",
    "    # Perform Dickey-Fuller test and print full report\n",
    "    result = adfuller(ts)\n",
    "    print('Augmented Dickey-Fuller Test:')\n",
    "    labels = ['ADF Test Statistic', 'p-value', '# Lags Used', '# Observations Used']\n",
    "    for value, label in zip(result, labels):\n",
    "        print(label + ': ' + str(value))\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Strong evidence against the null hypothesis\")\n",
    "        print(\"Reject the null hypothesis\")\n",
    "        print(\"Data has no unit root and is stationary\")\n",
    "    else:\n",
    "        print(\"Weak evidence against the null hypothesis\")\n",
    "        print(\"Fail to reject the null hypothesis\")\n",
    "        print(\"Data has a unit root and is non-stationary\")\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Interpretation of ACF and PACF](https://www.geeksforgeeks.org/understanding-partial-autocorrelation-functions-pacf-in-time-series-data/)\n",
    "- [Video explaining ADF test](https://www.youtube.com/watch?v=X8nGZ2UCJsk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
