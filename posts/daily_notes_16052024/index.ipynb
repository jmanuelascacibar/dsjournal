{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Daily Note - 16-05-2024\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "    toc: true\n",
    "    toc-levels: 4\n",
    "    toc-expand: 4\n",
    "jupyter: python3  \n",
    "author: \"JM Ascacibar\"\n",
    "date: \"2024-05-16\"\n",
    "categories: \n",
    "  - quarto\n",
    "  - bash\n",
    "  - python\n",
    "  - debugging\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Numerical data types in Python, datatime pandas, modulus operator `%`, `pd.options.display.max_info_columns`, `memory_usage()`, Save order, Parquet and Feather, `psutil` library, managing memory in notebooks*\n",
    "\n",
    "![](designer.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Working plan for the next weeks\n",
    "- [ ] Flood Competition. Modelling the data and making predictions\n",
    "- [ ] AMEX competition\n",
    "- [ ] Concrete competition. Modelling the data and making predictions\n",
    "- [ ] Shapley \n",
    "- [ ] Inference and prediction\n",
    "- [ ] PCA\n",
    "- [ ] Target Transformations\n",
    "- [ ] Richard Dawking explanation of FP and FN\n",
    "\n",
    "# Daily Note - 16/05/2024\n",
    "\n",
    "## 1. Difference between `int32` and `int64` in Python\n",
    "\n",
    "In Python libraries like pandas and numpy, we can use `int32` and `int64` to represent integers. The difference between them is the amount of memory they use. `int32` uses 32 bits (4 bytes) to represent an integer, while `int64` uses 64 bits (8 bytes). This means that `int64` can represent larger numbers than `int32`. For example, `int32` can represent numbers from -2,147,483,648 to 2,147,483,647, while `int64` can represent numbers from -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807.\n",
    "\n",
    "## 2. Float Numbers data types in Python\n",
    "\n",
    "In Python, there are several data types to represent numbers, one of them is float numbers. Float numbers are used to represent real numbers, and they can have decimal points. There are two main float data types in Python: `float32` and `float64`. \n",
    "\n",
    "A `float64` (or double precision) stores numbers with approximately 15-17 decimal digits of precision and requires 8 bytes per number.A `float32` (or single precision) stores numbers with about 6-9 decimal digits of precision and requires only 4 bytes per number.\n",
    "\n",
    "Converting from `float64` to `float32` can save half the memory usage without a significant loss in precision for many applications, although the exact impact depends on the specific data and requirements.\n",
    "\n",
    "A `float16` (or half precision) provides even less precision, about 3-4 decimal digits, and requires only 2 bytes per number.\n",
    "\n",
    "## 3. Convert year, month, day to `int8`\n",
    "\n",
    "When working with date columns in pandas, it is common to convert them to `int8` to save memory. `int8` data type can store integers from -128 to 127, which is enough to represent the year, month, and day.\n",
    "\n",
    "`int8` occupies only 1 byte of memory per entry, whereas `int32` uses 4 bytes and `int64` uses 8 bytes. This difference becomes significant when dealing with large datasets.\n",
    "\n",
    "## 4. Remainder and modulus operator `%`\n",
    "\n",
    "The remainder is the amount left over after performing a division operation between two numbers. For example, when you divide 17 by 5, the quotient is 3 and the remainder is 2.\n",
    "\n",
    "The modulus operator `%` is a mathematical tool used in programming to find the remainder of a division of one number by another. It is often used to determine if a number is even or odd, or to extract the last digit of a number like in the case of extracting the last two digits of a year. In pandas, you can extract the last two digits:\n",
    "```python\n",
    "data['S_2'].dt.year % 100\n",
    "```\n",
    "Where `data['S_2']` is a datetime column and `dt.year` extracts the year from the datetime column.\n",
    "\n",
    "## 5. `pd.options.display.max_info_columns`\n",
    "\n",
    "`pd.options.display.max_info_columns` is a pandas option that controls the maximum number of columns displayed when using the `df.info()` method. It is useful when working with large datasets with many columns.\n",
    "\n",
    "```python\n",
    "pd.options.display.max_info_columns = 300\n",
    "```\n",
    "\n",
    "## 6. `memory_usage()` method in pandas\n",
    "\n",
    "The `memory_usage()` method in pandas is used to calculate the memory usage of a DataFrame. By default, it returns the memory usage of each column in bytes. You can pass the `deep=True` argument to introspect the data deeply by interrogating object dtypes for system-level memory consumption. Documentation [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html)\n",
    "\n",
    "```python\n",
    "data.memory_usage(deep=True)['customer_ID']\n",
    "```\n",
    "\n",
    "## 7. Save order, Parquet and Feather\n",
    "\n",
    "In the cases where managing large datasets is critical, choosing the right file format based on **save order** and **compression** can be important. \n",
    "\n",
    "### Save Order\n",
    "\n",
    "The save order refers to how data is physically stored in a file. It can be either row-oriented or column-oriented. Row-oriented storage is when data is stored row by row, while column-oriented storage is when data is stored column by column. \n",
    "\n",
    "CSV file save data in a row-wise manner. Each row is written sequentially , and when reading the file, it typically reads row by row. If your analysis or processing often requires accessing complete rows at a time then CSV might be suitable. However if you only need to access specific columns, CSV is inefficient because it loads entire rows into memory. Also keep in mind, **CSV files doesn't support compression natively, and doesn't preserve datatypes.** \n",
    "\n",
    "\n",
    "### Parquet and Feather\n",
    "\n",
    "Parquet and feather are designed to store data column by column. This format is particularly beneficial for analytical processing where queries often involve specific columns across a wide range of rows. Both formats support compression and preserve datatypes.\n",
    "\n",
    "So if your data access is mostly columnar, then use Parquet or Feather. Use Parquet if you need efficient storage and excellent compression, or use Feather if you need fast read and write times.\n",
    "\n",
    "For the AMEX competition, where datasets are typically large, efficiency is crucial. Parquet is often the preferred choice due to its performance benefits in terms of storage, partial reads, and data type preservation\n",
    "\n",
    "## 8. `psutil` library\n",
    "\n",
    "`psutil` is a Python library that provides an interface for retrieving information on running processes and system utilization. It can be used to monitor system resources like CPU, memory, disk, and network usage. Documentation [here](https://psutil.readthedocs.io/en/latest/)\n",
    "\n",
    "I've created a function to know the available memory in the system. \n",
    "\n",
    "```python\n",
    "import psutil\n",
    "\n",
    "def available_memory_gb():\n",
    "    return psutil.virtual_memory().available / (1024**3)\n",
    "```\t\n",
    "\n",
    "\n",
    "## 9. Managing memory with notebooks\n",
    "\n",
    "When working with large datasets in Jupyter notebooks, it is important to manage memory efficiently to avoid running out of memory. \n",
    "\n",
    "In Python, memory management is primarily handled by the garbage collector, which automatically frees up memory when objects are no longer needed. However, in some cases, especially when working with large data structures, it can be beneficial to manually intervine to ensure meory is freed up more promptly.\n",
    "\n",
    "Here are some tips to manage memory in notebooks:\n",
    "\n",
    "\n",
    "### Use `del` to delete variables\n",
    "\n",
    "When you no longer need a variable, use the `del` statement to delete it from memory. This will free up memory that can be used for other operations.\n",
    "\n",
    "```python\n",
    "import gc\n",
    "\n",
    "del variable_name  # Delete the variable to free up memory\n",
    "gc.collect()  # Explicitly call garbage collector\n",
    "````\n",
    "\n",
    "### Restart the kernel\n",
    "\n",
    "If you are running out of memory, restarting the kernel can help free up memory. This will clear all variables and objects from memory, allowing you to start fresh.\n",
    "\n",
    "### Monitor System Memory\n",
    "\n",
    "You can use system tools like the task manager on Windows, or `top` and `htop` on Linux to monitor system memory usage.\n",
    "\n",
    "### Monitor GPU use (NVIDIA GPUs)\n",
    "\n",
    "The most straightforward way to monitor GPU usage is to use the `nvidia-smi` command in the terminal. This command provides real-time information about GPU utilization, memory usage, and temperature.\n",
    "\n",
    "You can also run it in a continous monitoring mode by running `nvidia-smi -l 1` in the terminal.\n",
    "\n",
    "For deeplearning training model is quite common to use `nvidia-smi dmon` to monitor the GPU usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
